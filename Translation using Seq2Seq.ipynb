{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Translate French sentences to English using Seq2Seq model</h3>\n",
    "<p>The notebook includes the steps to build a encoder-decoder model with attention from scratch in PyTorch. This is also called as a Sequence-to-Sequence model, which is used here to train a language translator from French to English.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "   creating: pytorch_seq2seq/data/\n",
      "  inflating: pytorch_seq2seq/data/eng-fra.txt  \n",
      "   creating: pytorch_seq2seq/data/names/\n",
      "  inflating: pytorch_seq2seq/data/names/Arabic.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Chinese.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Czech.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Dutch.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/English.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/French.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/German.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Greek.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Irish.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Italian.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Japanese.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Korean.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Polish.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Portuguese.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Russian.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Scottish.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Spanish.txt  \n",
      "  inflating: pytorch_seq2seq/data/names/Vietnamese.txt  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      " 32 2814k   32  911k    0     0   825k      0  0:00:03  0:00:01  0:00:02  824k\r",
      " 81 2814k   81 2304k    0     0  1093k      0  0:00:02  0:00:02 --:--:-- 1092k\r",
      "100 2814k  100 2814k    0     0  1177k      0  0:00:02  0:00:02 --:--:-- 1176k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Download and unzip dataset\n",
    "curl -o data.zip https://download.pytorch.org/tutorial/data.zip\n",
    "\n",
    "data_dir=\"pytorch_seq2seq\"\n",
    "rm -r $data_dir\n",
    "unzip data.zip -d $data_dir\n",
    "rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "# Class to define index and count of each word\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "\n",
    "        # Count SOS and EOS\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG1 = \"eng\"\n",
    "LANG2 = \"fra\"\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    data_path = \"pytorch_seq2seq/data/{0}-{1}.txt\".format(LANG1, LANG2)\n",
    "    lines = open(data_path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Define objects for both languages\n",
    "    if not reverse:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    else:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter sentences based on length\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "# Filter sentences based on input prefix\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    if len(p[0].split(\" \")) >= MAX_LENGTH or len(p[1].split(\" \")) >= MAX_LENGTH:\n",
    "        return False\n",
    "    elif p[0].startswith(eng_prefixes) or p[1].startswith(eng_prefixes):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Summary: fra 4345 | eng 2803\n",
      "\n",
      "Example:  ['elle est en train de cuisiner pour lui .', 'she is cooking for him .']\n"
     ]
    }
   ],
   "source": [
    "# Read dataset and construct language pairs\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Summary: {0} {1} | {2} {3}\" \\\n",
    "          .format(input_lang.name, input_lang.n_words, output_lang.name, output_lang.n_words))    \n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(LANG1, LANG2, True)\n",
    "pair = random.choice(pairs)\n",
    "print(\"\\nExample: \", pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: ['elle est en train de cuisiner pour lui .', 'she is cooking for him .']\n",
      "tensor([[ 119],\n",
      "        [  25],\n",
      "        [  14],\n",
      "        [ 100],\n",
      "        [ 101],\n",
      "        [2745],\n",
      "        [1150],\n",
      "        [ 247],\n",
      "        [   5],\n",
      "        [   1]])\n",
      "tensor([[ 75],\n",
      "        [ 40],\n",
      "        [750],\n",
      "        [739],\n",
      "        [474],\n",
      "        [  4],\n",
      "        [  1]])\n"
     ]
    }
   ],
   "source": [
    "# Convert sentence to list of indexes\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "# Convert sentence to a tensor\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "# Convert a data-pair to tensor-pair\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "tensor_pair = tensorsFromPair(pair)\n",
    "print(\"Example: {0}\\n{1}\\n{2}\".format(pair, tensor_pair[0], tensor_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    # Plot loss during the training\n",
    "    plt.figure()\n",
    "    plt.plot(points)\n",
    "    plt.show()\n",
    "    \n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Convert a word to embedding\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        \n",
    "        # Compute output and next hidden state\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class for decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, attention, hidden_size, output_size, max_length, dropout_prob):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.attention = attention\n",
    "        self.max_length = max_length\n",
    "        if self.attention:\n",
    "            self.initAttention(max_length, dropout_prob)\n",
    "            \n",
    "    def initAttention(self, max_length, dropout_prob):\n",
    "        # Initialize attention related attributes\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        \n",
    "        if self.attention:\n",
    "            embedded = self.dropout(embedded)\n",
    "\n",
    "            # Compute attention weights from input and hidden state\n",
    "            attn_input = torch.cat((embedded[0], hidden[0]), 1)\n",
    "            attn_weights = F.softmax(self.attn(attn_input), dim=1)\n",
    "\n",
    "            # Compute context vector and attention vector\n",
    "            context_vector = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "            attention = torch.cat((embedded[0], context_vector[0]), 1)\n",
    "            embedded = F.relu(self.attn_combine(attention).unsqueeze(0))\n",
    "            \n",
    "        else:\n",
    "            attn_weights = None\n",
    "            embedded = F.relu(embedded)\n",
    "\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for combined network of encoder and decoder\n",
    "class Seq2SeqNetwork(object):\n",
    "    def __init__(self, attention, hidden_size, learning_rate, max_length, dropout_prob, teacher_forcing_ratio):\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        \n",
    "        # Initialize encoder and decoder in the network\n",
    "        self.encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "        self.decoder = DecoderRNN(attention, hidden_size, output_lang.n_words, max_length, dropout_prob)\n",
    "\n",
    "        # Define optimizers and loss function\n",
    "        self.encoder_optimizer = optim.SGD(self.encoder.parameters(), lr=learning_rate)\n",
    "        self.decoder_optimizer = optim.SGD(self.decoder.parameters(), lr=learning_rate)        \n",
    "        self.criterion = nn.NLLLoss()\n",
    "\n",
    "    def trainUtil(self, input_tensor, target_tensor):\n",
    "        # Train network with a single data pair\n",
    "\n",
    "        loss = 0\n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "    \n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "        \n",
    "        # Initalize array for encoder outputs and encoder hidden state\n",
    "        encoder_outputs = torch.zeros(self.decoder.max_length, self.encoder.hidden_size)\n",
    "        encoder_hidden = self.encoder.initHidden()\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        # Initialize decoder input and hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = torch.tensor([[SOS_token]])\n",
    "        \n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        for di in range(target_length):\n",
    "            result = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_output, decoder_hidden, decoder_attention = result\n",
    "\n",
    "            loss += self.criterion(decoder_output, target_tensor[di])\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[di]\n",
    "\n",
    "            elif decoder_input.item() != EOS_token:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "\n",
    "        return loss.item() / target_length\n",
    "    \n",
    "    def train(self, n_iters, print_every=1000, plot_every=100):\n",
    "        start = time.time()\n",
    "        print_loss_total = 0  \n",
    "        plot_loss_total = 0 \n",
    "        plot_losses = []\n",
    "        \n",
    "        for iter in range(1, n_iters + 1):\n",
    "            input_tensor, target_tensor = tensorsFromPair(random.choice(pairs))\n",
    "            loss = self.trainUtil(input_tensor, target_tensor)\n",
    "\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) Loss: %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "        \n",
    "        showPlot(plot_losses)\n",
    "        \n",
    "    def evaluateUtil(self, max_length=MAX_LENGTH):\n",
    "        sentence, target = random.choice(pairs)\n",
    "        \n",
    "        # Computations without gradient\n",
    "        with torch.no_grad():\n",
    "            input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "            input_length = input_tensor.size()[0]\n",
    "\n",
    "            encoder_outputs = torch.zeros(self.decoder.max_length, self.encoder.hidden_size)\n",
    "            encoder_hidden = self.encoder.initHidden()\n",
    "            \n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = self.encoder(input_tensor[ei], encoder_hidden)\n",
    "                encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "            decoder_input = torch.tensor([[SOS_token]])\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            # Initalize array for attention\n",
    "            decoder_attentions = torch.zeros(self.decoder.max_length, self.decoder.max_length)\n",
    "            decoded_words = []\n",
    "            \n",
    "            for di in range(max_length):\n",
    "                result = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                decoder_output, decoder_hidden, decoder_attention = result\n",
    "                decoder_attentions[di] = decoder_attention.data\n",
    "                \n",
    "                # Fetch the result word with largest output\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                if topi.item() == EOS_token:\n",
    "                    decoded_words.append('<EOS>')\n",
    "                    break\n",
    "                else:\n",
    "                    decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "                # Current output from decoder is the next input\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        decoder_attentions = decoder_attentions[:di + 1]\n",
    "        output_sentence = ' '.join(decoded_words)\n",
    "        print(\"> {0}\\n= {1}\\n< {2}\\n\".format(sentence, target, output_sentence))\n",
    "        return sentence, target, output_sentence, decoder_attentions\n",
    "        \n",
    "    def evaluate(self, n_iters):\n",
    "        for i in range(n_iters):\n",
    "            self.evaluateUtil()\n",
    "            \n",
    "    def evaluate_attention(self):\n",
    "        # Show attention weights in decoder\n",
    "        sentence, target, output_sentence, attentions = self.evaluateUtil()\n",
    "        plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 35s (- 58m 35s) (1000 1%) Loss: 3.6040\n",
      "1m 13s (- 59m 37s) (2000 2%) Loss: 2.9665\n",
      "1m 51s (- 59m 58s) (3000 3%) Loss: 2.7957\n",
      "2m 30s (- 60m 7s) (4000 4%) Loss: 2.6471\n",
      "3m 9s (- 59m 55s) (5000 5%) Loss: 2.5244\n",
      "3m 48s (- 59m 36s) (6000 6%) Loss: 2.4589\n",
      "4m 27s (- 59m 17s) (7000 7%) Loss: 2.3891\n",
      "5m 7s (- 58m 56s) (8000 8%) Loss: 2.3623\n",
      "5m 45s (- 58m 17s) (9000 9%) Loss: 2.1791\n",
      "6m 24s (- 57m 39s) (10000 10%) Loss: 2.1668\n",
      "7m 3s (- 57m 4s) (11000 11%) Loss: 2.0499\n",
      "7m 42s (- 56m 30s) (12000 12%) Loss: 2.0386\n",
      "8m 21s (- 55m 53s) (13000 13%) Loss: 1.9516\n",
      "9m 0s (- 55m 19s) (14000 14%) Loss: 2.0125\n",
      "9m 39s (- 54m 45s) (15000 15%) Loss: 1.8926\n",
      "10m 18s (- 54m 9s) (16000 16%) Loss: 1.8213\n",
      "10m 57s (- 53m 32s) (17000 17%) Loss: 1.7492\n",
      "11m 36s (- 52m 53s) (18000 18%) Loss: 1.7327\n",
      "12m 21s (- 52m 43s) (19000 19%) Loss: 1.6691\n",
      "13m 2s (- 52m 8s) (20000 20%) Loss: 1.6887\n",
      "13m 42s (- 51m 35s) (21000 21%) Loss: 1.5746\n",
      "14m 22s (- 50m 59s) (22000 22%) Loss: 1.5476\n",
      "15m 3s (- 50m 23s) (23000 23%) Loss: 1.5627\n",
      "15m 43s (- 49m 47s) (24000 24%) Loss: 1.4992\n",
      "16m 23s (- 49m 11s) (25000 25%) Loss: 1.4300\n",
      "17m 3s (- 48m 32s) (26000 26%) Loss: 1.4819\n",
      "17m 43s (- 47m 54s) (27000 27%) Loss: 1.4468\n",
      "18m 22s (- 47m 14s) (28000 28%) Loss: 1.4020\n",
      "19m 2s (- 46m 36s) (29000 28%) Loss: 1.3224\n",
      "19m 41s (- 45m 57s) (30000 30%) Loss: 1.2912\n",
      "20m 21s (- 45m 18s) (31000 31%) Loss: 1.2484\n",
      "21m 0s (- 44m 38s) (32000 32%) Loss: 1.2898\n",
      "21m 40s (- 44m 0s) (33000 33%) Loss: 1.1856\n",
      "22m 19s (- 43m 20s) (34000 34%) Loss: 1.1862\n",
      "26m 4s (- 48m 25s) (35000 35%) Loss: 1.1183\n",
      "26m 43s (- 47m 30s) (36000 36%) Loss: 1.1550\n",
      "27m 22s (- 46m 35s) (37000 37%) Loss: 1.1547\n",
      "28m 1s (- 45m 43s) (38000 38%) Loss: 1.1719\n",
      "28m 41s (- 44m 52s) (39000 39%) Loss: 1.0444\n",
      "29m 21s (- 44m 1s) (40000 40%) Loss: 1.0125\n",
      "30m 0s (- 43m 11s) (41000 41%) Loss: 0.9991\n",
      "30m 40s (- 42m 21s) (42000 42%) Loss: 0.9998\n",
      "31m 19s (- 41m 31s) (43000 43%) Loss: 0.9980\n",
      "31m 59s (- 40m 43s) (44000 44%) Loss: 1.0018\n",
      "32m 38s (- 39m 54s) (45000 45%) Loss: 0.9324\n",
      "33m 17s (- 39m 5s) (46000 46%) Loss: 0.9504\n",
      "33m 57s (- 38m 17s) (47000 47%) Loss: 0.8884\n",
      "34m 37s (- 37m 30s) (48000 48%) Loss: 0.8445\n",
      "35m 16s (- 36m 43s) (49000 49%) Loss: 0.8658\n",
      "35m 56s (- 35m 56s) (50000 50%) Loss: 0.8410\n",
      "36m 35s (- 35m 9s) (51000 51%) Loss: 0.8519\n",
      "37m 16s (- 34m 24s) (52000 52%) Loss: 0.8970\n",
      "37m 55s (- 33m 38s) (53000 53%) Loss: 0.8681\n",
      "38m 35s (- 32m 52s) (54000 54%) Loss: 0.7947\n",
      "39m 14s (- 32m 6s) (55000 55%) Loss: 0.7683\n",
      "39m 53s (- 31m 20s) (56000 56%) Loss: 0.7380\n",
      "40m 34s (- 30m 36s) (57000 56%) Loss: 0.7172\n",
      "41m 20s (- 29m 56s) (58000 57%) Loss: 0.7372\n",
      "42m 1s (- 29m 12s) (59000 59%) Loss: 0.7693\n",
      "42m 43s (- 28m 29s) (60000 60%) Loss: 0.7386\n",
      "43m 24s (- 27m 45s) (61000 61%) Loss: 0.6653\n",
      "44m 6s (- 27m 2s) (62000 62%) Loss: 0.7118\n",
      "44m 48s (- 26m 18s) (63000 63%) Loss: 0.6697\n",
      "45m 30s (- 25m 35s) (64000 64%) Loss: 0.6653\n",
      "46m 12s (- 24m 52s) (65000 65%) Loss: 0.6163\n",
      "46m 53s (- 24m 9s) (66000 66%) Loss: 0.6190\n",
      "47m 36s (- 23m 26s) (67000 67%) Loss: 0.5901\n",
      "48m 18s (- 22m 43s) (68000 68%) Loss: 0.5819\n",
      "48m 59s (- 22m 0s) (69000 69%) Loss: 0.6068\n",
      "49m 41s (- 21m 17s) (70000 70%) Loss: 0.5876\n",
      "50m 23s (- 20m 34s) (71000 71%) Loss: 0.6114\n",
      "51m 5s (- 19m 52s) (72000 72%) Loss: 0.5816\n",
      "51m 55s (- 19m 12s) (73000 73%) Loss: 0.5561\n",
      "52m 39s (- 18m 30s) (74000 74%) Loss: 0.5675\n",
      "53m 25s (- 17m 48s) (75000 75%) Loss: 0.5763\n",
      "54m 8s (- 17m 5s) (76000 76%) Loss: 0.6011\n",
      "54m 50s (- 16m 22s) (77000 77%) Loss: 0.5485\n",
      "55m 32s (- 15m 40s) (78000 78%) Loss: 0.5418\n",
      "56m 16s (- 14m 57s) (79000 79%) Loss: 0.5418\n",
      "56m 59s (- 14m 14s) (80000 80%) Loss: 0.4820\n",
      "57m 43s (- 13m 32s) (81000 81%) Loss: 0.5255\n",
      "58m 27s (- 12m 49s) (82000 82%) Loss: 0.4969\n",
      "59m 12s (- 12m 7s) (83000 83%) Loss: 0.4667\n",
      "59m 56s (- 11m 25s) (84000 84%) Loss: 0.4596\n",
      "60m 40s (- 10m 42s) (85000 85%) Loss: 0.4339\n",
      "61m 25s (- 9m 59s) (86000 86%) Loss: 0.4354\n",
      "62m 10s (- 9m 17s) (87000 87%) Loss: 0.5075\n",
      "62m 56s (- 8m 34s) (88000 88%) Loss: 0.4504\n",
      "63m 45s (- 7m 52s) (89000 89%) Loss: 0.4318\n",
      "64m 35s (- 7m 10s) (90000 90%) Loss: 0.4232\n",
      "65m 18s (- 6m 27s) (91000 91%) Loss: 0.4402\n",
      "66m 3s (- 5m 44s) (92000 92%) Loss: 0.4506\n",
      "66m 46s (- 5m 1s) (93000 93%) Loss: 0.4093\n",
      "67m 32s (- 4m 18s) (94000 94%) Loss: 0.3984\n",
      "68m 25s (- 3m 36s) (95000 95%) Loss: 0.3946\n",
      "69m 13s (- 2m 53s) (96000 96%) Loss: 0.4107\n",
      "69m 56s (- 2m 9s) (97000 97%) Loss: 0.4158\n",
      "70m 40s (- 1m 26s) (98000 98%) Loss: 0.3804\n",
      "71m 33s (- 0m 43s) (99000 99%) Loss: 0.4138\n",
      "72m 15s (- 0m 0s) (100000 100%) Loss: 0.3622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "learning_rate = 0.01\n",
    "teacher_forcing_ratio = 0.5\n",
    "dropout_prob = 0.1\n",
    "\n",
    "model = Seq2SeqNetwork(True, hidden_size, learning_rate, MAX_LENGTH, dropout_prob, teacher_forcing_ratio)\n",
    "model.train(100000, print_every=1000, plot_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> j y travaille encore .\n",
      "= i m still working on it .\n",
      "< i m still thinking about it . <EOS>\n",
      "\n",
      "> c est un homme cruel .\n",
      "= he is a cruel person .\n",
      "< he is a cruel person . <EOS>\n",
      "\n",
      "> je suis en train d etudier le francais .\n",
      "= i m studying french .\n",
      "< i m learning french . <EOS>\n",
      "\n",
      "> tu es bonne .\n",
      "= you are good .\n",
      "< you are good . <EOS>\n",
      "\n",
      "> il est incroyablement talentueux .\n",
      "= he s incredibly talented .\n",
      "< he s incredibly talented . <EOS>\n",
      "\n",
      "> c est une eleve de deuxieme annee .\n",
      "= she is a second year student .\n",
      "< he is a sophomore . <EOS>\n",
      "\n",
      "> tu n es pas ma mere .\n",
      "= you aren t my mother .\n",
      "< you re not my mother . <EOS>\n",
      "\n",
      "> c est une blonde .\n",
      "= she s a dumb blonde .\n",
      "< she is a blonde blonde . <EOS>\n",
      "\n",
      "> vous etes fort emotifs .\n",
      "= you re very emotional .\n",
      "< you re very emotional . <EOS>\n",
      "\n",
      "> vous etes charmante .\n",
      "= you re charming .\n",
      "< you re charming . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c est un pauvre type .\n",
      "= he s a jerk .\n",
      "< he s a jerk . . <EOS>\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 411.429x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
